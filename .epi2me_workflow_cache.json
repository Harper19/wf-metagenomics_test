{"hash":"m1pPaqU7CgwAPIwGWAH2CvFnOFcN0ak6/HiQThW1A5c=","workflow":{"repo":"wf-metagenomics_test","user":"Harper19","path":"/Users/kbian8/epi2melabs/workflows/Harper19/wf-metagenomics_test","schema":{"$schema":"http://json-schema.org/draft-07/schema","$id":"https://raw.githubusercontent.com/epi2me-labs/wf-metagenomics/master/nextflow_schema.json","title":"epi2me-labs/wf-metagenomics","workflow_title":"Metagenomics workflow","description":"Taxonomic classification from shotgun metagenomics sequencing.","demo_url":"https://ont-exd-int-s3-euwst1-epi2me-labs.s3.amazonaws.com/wf-metagenomics/wf-metagenomics-demo.tar.gz","aws_demo_url":"https://ont-exd-int-s3-euwst1-epi2me-labs.s3.amazonaws.com/wf-metagenomics/wf-metagenomics-demo/aws.nextflow.config","url":"https://github.com/epi2me-labs/wf-metagenomics","type":"object","resources":{"recommended":{"cpus":12,"memory":"32GB"},"minimum":{"cpus":6,"memory":"16GB"},"run_time":"~40min for 1 million reads in total (24 barcodes) using Kraken2 and the Standard-8 database (using a previously downloaded db).","arm_support":true},"definitions":{"input_options":{"title":"Input Options","type":"object","fa_icon":"fas fa-terminal","description":"Define where the pipeline should find input data and save output data.","properties":{"fastq":{"type":"string","format":"path","title":"FASTQ","description":"FASTQ files to use in the analysis.","help_text":"This accepts one of three cases: (i) the path to a single FASTQ file; (ii) the path to a top-level directory containing FASTQ files; (iii) the path to a directory containing one level of sub-directories which in turn contain FASTQ files. In the first and second case, a sample name can be supplied with `--sample`. In the last case, the data is assumed to be multiplexed with the names of the sub-directories as barcodes. In this case, a sample sheet can be provided with `--sample_sheet`.","demo_data":"test_data"},"bam":{"type":"string","format":"path","description":"BAM or unaligned BAM (uBAM) files to use in the analysis.","help_text":"This accepts one of three cases: (i) the path to a single BAM file; (ii) the path to a top-level directory containing BAM files; (iii) the path to a directory containing one level of sub-directories which in turn contain BAM files. In the first and second case, a sample name can be supplied with `--sample`. In the last case, the data is assumed to be multiplexed with the names of the sub-directories as barcodes. In this case, a sample sheet can be provided with `--sample_sheet`."},"classifier":{"type":"string","default":"kraken2","title":"Classification method","description":"Kraken2 or Minimap2 workflow to be used for classification of reads.","enum":["kraken2","minimap2"],"help_text":"Use Kraken2 for fast classification and minimap2 for finer resolution, see Readme for further info."},"analyse_unclassified":{"type":"boolean","default":false,"title":"Analyse unclassified reads","description":"Analyse unclassified reads from input directory. By default the workflow will not process reads in the unclassified directory.","help_text":"If selected and if the input is a multiplex directory the workflow will also process the unclassified directory."},"exclude_host":{"type":"string","format":"file-path","title":"Exclude host reads","description":"A FASTA or MMI file of the host reference. Reads that align with this reference will be excluded from the analysis."}},"oneOf":[{"required":["fastq"]},{"required":["bam"]}]},"real_time_analysis_options":{"title":"Real Time Analysis Options","type":"object","description":"Options relating to the default real-time Kraken2 workflow.","default":"","properties":{"real_time":{"type":"boolean","title":"Enable real time processing","default":false,"description":"Enable to continuously watch the input directory for new input files. Reads will be analysed as they appear","help_text":"This option enables the use of Nextflowâ€™s directory watching feature to constantly monitor input directories for new files. As soon as files are written by an external process Nextflow will begin analysing these files. The workflow will accumulate data over time to produce an updating report."},"batch_size":{"type":"integer","default":0,"title":"Size of each batch","description":"Maximum number of sequence records to process in a batch.","help_text":"Large files will be split such that batch_size records are processed together. Set to 0 to avoid rebatching input files. A value of 32000 is recommended to rebatch large files."},"read_limit":{"type":"integer","title":"Number of reads analysed to stop the workflow","description":"Stop processing data when a particular number of reads have been analysed. By default the workflow will run indefinitely.","help_text":"Sets the upper bound on the number of reads that will be analysed before the workflow is automatically stopped and no more data is analysed."},"port":{"type":"integer","default":8080,"title":"Network port","description":"Network port for communication between Kraken2 server and clients (available in real time  pipeline).","help_text":"The workflow uses a server process to handle Kraken2 classification requests. This allows the workflow to persist the sequence database in memory throughout the duration of processing. The option specifies the local network port on which the server and clients will communicate."},"host":{"type":"string","default":"localhost","title":"Network hostname (or IP address)","description":"Network hostname (or IP address) for communication between Kraken2 server and clients. (See also 'external_kraken2' parameter). (Available in real time  pipeline).","help_text":"The workflow uses a server process to handle Kraken2 classification requests. This allows the workflow to persist the sequence database in memory throughout the duration of processing. The option specifies the local network hostname (or IP address) of the Kraken server."},"external_kraken2":{"type":"boolean","default":false,"title":"External Kraken2 server","description":"Whether a pre-existing Kraken2 server should be used, rather than creating one as part of the workflow. (Available in real time  pipeline).","help_text":"By default the workflow assumes that it is running on a single host computer, and further that it should start its own Kraken2 server. It may be desirable to start a Kraken2 server outside of the workflow, in which case this option should be enabled. This option may be used in conjunction with the `host` option to specify that the Kraken2 server is running on a remote computer. "},"server_threads":{"type":"integer","default":2,"title":"CPU threads used by the Kraken2 server","description":"Number of CPU threads used by the Kraken2 server for classifying reads. (Available in the real_time pipeline).","help_text":"For the real-time Kraken2 workflow, this is the number of CPU threads used by the Kraken2 server for classifying reads."},"kraken_clients":{"type":"integer","default":2,"title":"Clients used by the Kraken2 server","description":"Number of clients that can connect at once to the Kraken-server for classifying reads. (Available in the real_time pipeline).","help_text":"For the real-time Kraken2 workflow, this is the number of clients sending reads to the server. It should not be set to more than 4 fewer than the executor CPU limit."}}},"sample_options":{"title":"Sample Options","type":"object","default":"","properties":{"sample_sheet":{"type":"string","format":"file-path","title":"Sample sheet","description":"A CSV file used to map barcodes to sample aliases. The sample sheet can be provided when the input data is a directory containing sub-directories with FASTQ files. Disabled in the real time pipeline.","help_text":"The sample sheet is a CSV file with, minimally, columns named `barcode`,`alias`. Extra columns are allowed. A `type` column is required for certain workflows and should have the following values; `test_sample`, `positive_control`, `negative_control`, `no_template_control`."},"sample":{"type":"string","title":"Sample name","description":"A single sample name for non-multiplexed data. Permissible if passing a single .fastq(.gz) file or directory of .fastq(.gz) files. Disabled in the real time pipeline."}},"description":"Parameters that relate to samples such as sample sheets and sample names."},"reference_options":{"title":"Reference Options","type":"object","description":"Files will be downloaded as part of the first run of workflow and automatically stored for subsequent runs.","default":"","properties":{"database_set":{"type":"string","default":"Standard-8","title":"Choose a database","description":"Sets the reference, databases and taxonomy datasets that will be used for classifying reads. Choices: ['ncbi_16s_18s','ncbi_16s_18s_28s_ITS', 'SILVA_138_1', 'Standard-8', 'PlusPF-8', 'PlusPFP-8']. Memory requirement will be slightly higher than the size of the database. Standard-8, PlusPF-8 and PlusPFP-8 databases require more than 8GB.","enum":["ncbi_16s_18s","ncbi_16s_18s_28s_ITS","SILVA_138_1","Standard-8","PlusPF-8","PlusPFP-8"],"help_text":"This setting is overridable by providing an explicit taxonomy, database or reference path in the other reference options."},"store_dir":{"type":"string","format":"directory-path","title":"Store directory name","description":"Where to store initial download of database.","help_text":"database set selected will be downloaded as part of the workflow and saved in this location, on subsequent runs it will use this as the database. ","hidden":true,"default":"store_dir"},"database":{"type":"string","format":"path","title":"Kraken2 database","description":"Not required but can be used to specifically override Kraken2 database [.tar.gz or Directory].","help_text":"By default uses database chosen in database_set parameter."},"taxonomy":{"type":"string","format":"path","title":"Taxonomy database","description":"Not required but can be used to specifically override taxonomy database. Change the default to use a different taxonomy file  [.tar.gz or directory].","help_text":"By default NCBI taxonomy file will be downloaded and used."},"reference":{"type":"string","format":"file-path","title":"Minimap2 reference","description":"Override the FASTA reference file selected by the database_set parameter. It can be a FASTA format reference sequence collection or a minimap2 MMI format index.","help_text":"This option should be used in conjunction with the database parameter to specify a custom database."},"ref2taxid":{"type":"string","format":"file-path","title":"File linking reference IDs to specific taxids","description":"Not required but can be used to specify a  ref2taxid mapping. Format is .tsv (refname  taxid), no header row.","help_text":"By default uses ref2taxid for option chosen in database_set parameter."},"database_sets":{"type":"object","hidden":true,"description":"A map containing the available sources and their default resource paths."},"taxonomic_rank":{"type":"string","default":"S","title":"Taxonomic rank","description":"Returns results at the taxonomic rank chosen. In the Kraken2 pipeline: set the level that Bracken will estimate abundance at. Default: S (species). Other possible options are K (kingdom level), P (phylum), C (class), O (order), F (family), and G (genus).","enum":["S","G","k","F","O","C","P"]}}},"kraken2_options":{"title":"Kraken2 Options","type":"object","fa_icon":"fas fa-university","help_text":"Kraken2: It is possible to enable classification by Kraken2, and disable alignment which is a faster but coarser method of classification reliant on the presence of a Kraken2 database.","properties":{"bracken_length":{"type":"integer","title":"Bracken length","description":"Set the length value Bracken will use","minimum":1,"help_text":"Should be set to the length used to generate the kmer distribution file supplied in the Kraken database input directory. For the default datasets these will be set automatically. ncbi_16s_18s = 1000 , ncbi_16s_18s_28s_ITS = 1000 , PlusPF-8 = 300"},"kraken2_memory_mapping":{"type":"boolean","default":false,"title":"Enable memory mapping","description":"Avoids loading database into RAM","help_text":"Kraken 2 will by default load the database into process-local RAM; this flag will avoid doing so. It may be useful if the available RAM memory is lower than the size of the chosen database."},"include_kraken2_assignments":{"type":"boolean","default":false,"title":"Include Kraken2 reads assignments","description":"A per sample TSV file that indicates how each input sequence was classified as well as the taxon that has been assigned to each read. The TSV's will only be output on completion of the workflow and therefore not at all if using the real time option whilst running indefinitely.","help":"It also includes the taxon that each k-mer mapped back to, if the k-mer was able to be classified."},"kraken2_confidence":{"type":"number","default":0,"title":"Confidence score threshold","description":"Kraken2 Confidence score threshold. Default: 0.0. Valid interval: 0-1","help_text":"Apply a threshold to determine if a sequence is classified or unclassified. Please visit the following link for further details about how it works: https://github.com/DerrickWood/kraken2/wiki/Manual#confidence-scoring."}},"description":"Kraken2 classification options. Only relevant if classifier parameter is set to kraken2"},"minimap2_options":{"title":"Minimap2 Options","type":"object","fa_icon":"fas fa-dna","properties":{"minimap2filter":{"type":"string","title":"Select reads belonging to the following taxonomy identifiers (taxids)","description":"Filter output of minimap2 by taxids inc. child nodes, E.g. \"9606,1404\"","help_text":"Provide a list of taxids if you are only interested in certain ones in your minimap2 analysis outputs."},"minimap2exclude":{"type":"boolean","default":false,"title":"Exclude reads from previous selected taxids","description":"Invert minimap2filter and exclude the given taxids instead","help_text":"Exclude a list of taxids from analysis outputs."},"split_prefix":{"type":"boolean","title":"Enable multipart index","default":false,"description":"Enable if using a very large reference with minimap2","help_text":"If reference fasta large enough to require multipart index, set to true to use split-prefix option with minimap2."},"keep_bam":{"type":"boolean","title":"Enable keep BAM files","default":false,"description":"Copy bam files into the output directory. It also creates the configuration and reduced reference files needed to load the alignments in IGV."},"minimap2_by_reference":{"type":"boolean","default":false,"title":"Compute coverage and sequencing depth of the references.","description":"Add a table with the mean sequencing depth per reference, standard deviation and coefficient of variation. It adds a scatterplot of the sequencing depth vs. the coverage and a heatmap showing the depth per percentile to the report"},"min_percent_identity":{"type":"number","default":90,"minimum":0,"maximum":100,"title":"Filter taxa based on the percent of identity with the references.","description":"Minimum percentage of identity with the matched reference to define a sequence as classified; sequences with a value lower than this are defined as unclassified."},"min_ref_coverage":{"type":"number","default":0,"minimum":0,"maximum":100,"title":"Filter taxa based on the percent of coverage with the reference.","description":"Minimum coverage value to define a sequence as classified; sequences with a coverage value lower than this are defined as unclassified. Use this option if you expect reads whose lengths are similar to the references' lengths."}},"description":"Minimap2 classification options. Only relevant if classifier parameter is set to minimap2.","help_text":"Minimap2: The default strategy is using minimap2 to perform full alignments against .fasta formatted references sequences."},"amr_options":{"title":"Antimicrobial Resistance Options","type":"object","fa_icon":"fas fa-pills","properties":{"amr":{"type":"boolean","title":"Enable search for antimicrobial resistance genes (AMR)","default":false,"description":"Scan reads for antimicrobial resistance or virulence genes","help_text":"Reads will be scanned using abricate and the chosen database (`--amr_db`) to identify any acquired antimicrobial resistance or virulence genes found present in the dataset. NOTE: It cannot identify mutational resistance genes."},"amr_db":{"type":"string","default":"resfinder","title":"AMR database","description":"Database of antimicrobial resistance or virulence genes to use.","enum":["resfinder","ecoli_vf","plasmidfinder","card","argannot","vfdb","ncbi","megares","ecoh"]},"amr_minid":{"type":"integer","default":80,"minimum":0,"maximum":100,"title":"AMR identity threshold","description":"Threshold of required identity to report a match between a gene in the database and fastq reads. Valid interval: 0-100"},"amr_mincov":{"type":"integer","default":80,"minimum":0,"maximum":100,"title":"AMR coverage (breadth-of) threshold","description":"Minimum coverage (breadth-of) threshold required to report a match between a gene in the database and fastq reads. Valid interval: 0-100."}}},"report_options":{"title":"Report Options","type":"object","fa_icon":"fas fa-pills","properties":{"abundance_threshold":{"type":"number","default":0,"title":"Abundance threshold","description":"Remove those taxa whose abundance is equal or lower than the chosen value.","help_text":"To remove taxa with abundances lower than or equal to a relative value (compared to the total number of reads) use a decimal between 0-1 (1 not inclusive). To remove taxa with abundances lower than or equal to an absolute value, provide a number larger or equal to 1."},"n_taxa_barplot":{"type":"integer","default":9,"title":"Number of taxa to be displayed in the barplot","description":"Number of most abundant taxa to be displayed in the barplot. The rest of taxa will be grouped under the \"Other\" category."}}},"output_options":{"title":"Output Options","type":"object","description":"Parameters for saving and naming workflow outputs.","default":"","properties":{"out_dir":{"type":"string","format":"directory-path","default":"output","title":"Output folder name","description":"Directory for output of all user-facing files."}}},"advanced_options":{"title":"Advanced Options","type":"object","description":"Advanced options for configuring processes inside the workflow.","default":"","properties":{"min_len":{"type":"integer","default":0,"title":"Minimum read length","description":"Specify read length lower limit.","help_text":"Any reads shorter than this limit will not be included in the analysis."},"min_read_qual":{"type":"number","title":"Minimum read quality","description":"Specify read quality lower limit.","help_text":"Any reads with a quality lower than this limit will not be included in the analysis."},"max_len":{"type":"integer","title":"Maximum read length","description":"Specify read length upper limit","help_text":"Any reads longer than this limit will not be included in the analysis."},"threads":{"type":"integer","default":4,"title":"Number of CPU threads per workflow task","description":"Maximum number of CPU threads to use in each parallel workflow task.","help_text":"Several tasks in this workflow benefit from using multiple CPU threads. This option sets the number of CPU threads for all such processes. See server threads parameter for Kraken specific threads in the real_time pipeline."}}},"miscellaneous_options":{"title":"Miscellaneous Options","type":"object","fa_icon":"fas fa-file-import","description":"Everything else.","help_text":"These options are common to all nf-core pipelines and allow you to customise some of the core preferences for how the pipeline runs. Typically these options would be set in a Nextflow config file loaded for all pipeline runs, such as `~/.nextflow/config`.","properties":{"disable_ping":{"type":"boolean","title":"Disable ping","default":false,"description":"Enable to prevent sending a workflow ping.","hidden":false},"help":{"type":"boolean","title":"Display help text","default":false,"fa_icon":"fas fa-question-circle","hidden":true},"version":{"type":"boolean","title":"Display version","default":false,"description":"Display version and exit.","fa_icon":"fas fa-question-circle","hidden":true}}}},"allOf":[{"$ref":"#/definitions/input_options"},{"$ref":"#/definitions/real_time_analysis_options"},{"$ref":"#/definitions/sample_options"},{"$ref":"#/definitions/reference_options"},{"$ref":"#/definitions/kraken2_options"},{"$ref":"#/definitions/minimap2_options"},{"$ref":"#/definitions/output_options"},{"$ref":"#/definitions/advanced_options"},{"$ref":"#/definitions/miscellaneous_options"},{"$ref":"#/definitions/amr_options"},{"$ref":"#/definitions/report_options"}],"properties":{"aws_image_prefix":{"type":"string","title":"AWS image prefix","hidden":true},"aws_queue":{"type":"string","title":"AWS queue","hidden":true},"monochrome_logs":{"type":"boolean"},"validate_params":{"type":"boolean","default":true},"show_hidden_params":{"type":"boolean"}}},"readme":"# Metagenomics workflow\n\nTaxonomic classification from shotgun metagenomics sequencing.\n\n\n\n## Introduction\n\nThis workflow can be used for the following:\n\n+ Taxonomic classification of 16S rDNA and 18S rDNA amplicons using [default or custom databases](#FAQs). Default databases:\n    - NCBI targeted loci: 16S rDNA, 18S rDNA, ITS (ncbi_16s_18s, ncbi_16s_18s_28s_ITS; see [here](https://www.ncbi.nlm.nih.gov/refseq/targetedloci/) for details).\n    - General databases: Standard-8, PlusPF-8, PlusPFP-8 (see [here](https://benlangmead.github.io/aws-indexes/k2) for details).\n+ Generate taxonomic profiles of one or more metagenomic samples.\n+ Identify [AMR genes](#4-identify-antimicrobial-resistance-genes-amr-optional).\n\nAdditional features:\n+ Two different approaches are available: `kraken2` (k-mer based) or `minimap2` (using alignment).\n+ Option to run it in [real time](#311-running-wf-metagenomics-in-real-time): `real_time`.\n+ Results include:\n    - An abundance table with counts per taxa in all the samples.\n    - Interactive sankey and sunburst plots to explore the different identified lineages.\n    - A bar plot comparing the abundances of the most abundant taxa in all the samples.\n\n\n\n\n## Compute requirements\n\nRecommended requirements:\n\n+ CPUs = 12\n+ Memory = 32GB\n\nMinimum requirements:\n\n+ CPUs = 6\n+ Memory = 16GB\n\nApproximate run time: ~40min for 1 million reads in total (24 barcodes) using Kraken2 and the Standard-8 database (using a previously downloaded db).\n\nARM processor support: True\n\n\n\n\n## Install and run\n\nThese are instructions to install and run the workflow on command line. You can also access the workflow via the [EPI2ME application](https://labs.epi2me.io/downloads/).  \n\nThe workflow uses [nextflow](https://www.nextflow.io/) to manage compute and software resources. Therefore, nextflow will need to be installed before attempting to run the workflow. \n\nThe workflow can currently be run using either [Docker](https://www.docker.com/products/docker-desktop) or\n[Singularity](https://docs.sylabs.io/guides/3.0/user-guide/index.html) to provide isolation of \nthe required software. Both methods are automated out-of-the-box provided \neither Docker or Singularity is installed. This is controlled by the [`-profile`](https://www.nextflow.io/docs/latest/config.html#config-profiles) parameter as exemplified in the example below. \n\nIt is not required to clone or download the git repository in order to run the workflow. \nMore information on running EPI2ME workflows can be found on our [website](https://labs.epi2me.io/wfindex).\n\nThe following command can be used to obtain the workflow. This will pull the repository into the assets folder of nextflow and provide a list of all parameters available for the workflow as well as an example command:\n\n```\nnextflow run epi2me-labs/wf-metagenomics --help \n```\n\nA demo dataset is provided for testing of the workflow. It can be downloaded using: \n\n```\nwget https://ont-exd-int-s3-euwst1-epi2me-labs.s3.amazonaws.com/wf-metagenomics/wf-metagenomics-demo.tar.gz\ntar -xzvf wf-metagenomics-demo.tar.gz\n```\n\nThe workflow can be run with the demo data using: \n\n```\nnextflow run epi2me-labs/wf-metagenomics \\\n--fastq wf-metagenomics-demo/test_data/ \\\n-profile standard \n```\n\nFor further information about running a workflow on the command line see https://labs.epi2me.io/wfquickstart/\n\n\n\n## Related protocols\n\nThis workflow is designed to take input sequences that have been produced from [Oxford Nanopore Technologies](https://nanoporetech.com/) devices.\n\nFind related protocols in the [Nanopore community](https://community.nanoporetech.com/docs/).\n\n\n\n## Input example\n\n<!---Example of input directory structure, delete and edit as appropriate per workflow.--->\nThis workflow accepts either FASTQ or BAM files as input.\n\nThe FASTQ or BAM input parameters for this workflow accept one of three cases: (i) the path to a single FASTQ or BAM file; (ii) the path to a top-level directory containing FASTQ or BAM files; (iii) the path to a directory containing one level of sub-directories which in turn contain FASTQ or BAM files. In the first and second cases (i and ii), a sample name can be supplied with `--sample`. In the last case (iii), the data is assumed to be multiplexed with the names of the sub-directories as barcodes. In this case, a sample sheet can be provided with `--sample_sheet`.\n\n```\n(i)                     (ii)                 (iii)    \ninput_reads.fastq   â”€â”€â”€ input_directory  â”€â”€â”€ input_directory\n                        â”œâ”€â”€ reads0.fastq     â”œâ”€â”€ barcode01\n                        â””â”€â”€ reads1.fastq     â”‚   â”œâ”€â”€ reads0.fastq\n                                             â”‚   â””â”€â”€ reads1.fastq\n                                             â”œâ”€â”€ barcode02\n                                             â”‚   â”œâ”€â”€ reads0.fastq\n                                             â”‚   â”œâ”€â”€ reads1.fastq\n                                             â”‚   â””â”€â”€ reads2.fastq\n                                             â””â”€â”€ barcode03\n                                              â””â”€â”€ reads0.fastq\n```\n\n\n\n## Input parameters\n\n### Input Options\n\n| Nextflow parameter name  | Type | Description | Help | Default |\n|--------------------------|------|-------------|------|---------|\n| fastq | string | FASTQ files to use in the analysis. | This accepts one of three cases: (i) the path to a single FASTQ file; (ii) the path to a top-level directory containing FASTQ files; (iii) the path to a directory containing one level of sub-directories which in turn contain FASTQ files. In the first and second case, a sample name can be supplied with `--sample`. In the last case, the data is assumed to be multiplexed with the names of the sub-directories as barcodes. In this case, a sample sheet can be provided with `--sample_sheet`. |  |\n| bam | string | BAM or unaligned BAM (uBAM) files to use in the analysis. | This accepts one of three cases: (i) the path to a single BAM file; (ii) the path to a top-level directory containing BAM files; (iii) the path to a directory containing one level of sub-directories which in turn contain BAM files. In the first and second case, a sample name can be supplied with `--sample`. In the last case, the data is assumed to be multiplexed with the names of the sub-directories as barcodes. In this case, a sample sheet can be provided with `--sample_sheet`. |  |\n| classifier | string | Kraken2 or Minimap2 workflow to be used for classification of reads. | Use Kraken2 for fast classification and minimap2 for finer resolution, see Readme for further info. | kraken2 |\n| analyse_unclassified | boolean | Analyse unclassified reads from input directory. By default the workflow will not process reads in the unclassified directory. | If selected and if the input is a multiplex directory the workflow will also process the unclassified directory. | False |\n| exclude_host | string | A FASTA or MMI file of the host reference. Reads that align with this reference will be excluded from the analysis. |  |  |\n\n\n### Real Time Analysis Options\n\n| Nextflow parameter name  | Type | Description | Help | Default |\n|--------------------------|------|-------------|------|---------|\n| real_time | boolean | Enable to continuously watch the input directory for new input files. Reads will be analysed as they appear | This option enables the use of Nextflowâ€™s directory watching feature to constantly monitor input directories for new files. As soon as files are written by an external process Nextflow will begin analysing these files. The workflow will accumulate data over time to produce an updating report. | False |\n| batch_size | integer | Maximum number of sequence records to process in a batch. | Large files will be split such that batch_size records are processed together. Set to 0 to avoid rebatching input files. A value of 32000 is recommended to rebatch large files. | 0 |\n| read_limit | integer | Stop processing data when a particular number of reads have been analysed. By default the workflow will run indefinitely. | Sets the upper bound on the number of reads that will be analysed before the workflow is automatically stopped and no more data is analysed. |  |\n| port | integer | Network port for communication between Kraken2 server and clients (available in real time  pipeline). | The workflow uses a server process to handle Kraken2 classification requests. This allows the workflow to persist the sequence database in memory throughout the duration of processing. The option specifies the local network port on which the server and clients will communicate. | 8080 |\n| host | string | Network hostname (or IP address) for communication between Kraken2 server and clients. (See also 'external_kraken2' parameter). (Available in real time  pipeline). | The workflow uses a server process to handle Kraken2 classification requests. This allows the workflow to persist the sequence database in memory throughout the duration of processing. The option specifies the local network hostname (or IP address) of the Kraken server. | localhost |\n| external_kraken2 | boolean | Whether a pre-existing Kraken2 server should be used, rather than creating one as part of the workflow. (Available in real time  pipeline). | By default the workflow assumes that it is running on a single host computer, and further that it should start its own Kraken2 server. It may be desirable to start a Kraken2 server outside of the workflow, in which case this option should be enabled. This option may be used in conjunction with the `host` option to specify that the Kraken2 server is running on a remote computer.  | False |\n| server_threads | integer | Number of CPU threads used by the Kraken2 server for classifying reads. (Available in the real_time pipeline). | For the real-time Kraken2 workflow, this is the number of CPU threads used by the Kraken2 server for classifying reads. | 2 |\n| kraken_clients | integer | Number of clients that can connect at once to the Kraken-server for classifying reads. (Available in the real_time pipeline). | For the real-time Kraken2 workflow, this is the number of clients sending reads to the server. It should not be set to more than 4 fewer than the executor CPU limit. | 2 |\n\n\n### Sample Options\n\n| Nextflow parameter name  | Type | Description | Help | Default |\n|--------------------------|------|-------------|------|---------|\n| sample_sheet | string | A CSV file used to map barcodes to sample aliases. The sample sheet can be provided when the input data is a directory containing sub-directories with FASTQ files. Disabled in the real time pipeline. | The sample sheet is a CSV file with, minimally, columns named `barcode`,`alias`. Extra columns are allowed. A `type` column is required for certain workflows and should have the following values; `test_sample`, `positive_control`, `negative_control`, `no_template_control`. |  |\n| sample | string | A single sample name for non-multiplexed data. Permissible if passing a single .fastq(.gz) file or directory of .fastq(.gz) files. Disabled in the real time pipeline. |  |  |\n\n\n### Reference Options\n\n| Nextflow parameter name  | Type | Description | Help | Default |\n|--------------------------|------|-------------|------|---------|\n| database_set | string | Sets the reference, databases and taxonomy datasets that will be used for classifying reads. Choices: ['ncbi_16s_18s','ncbi_16s_18s_28s_ITS', 'SILVA_138_1', 'Standard-8', 'PlusPF-8', 'PlusPFP-8']. Memory requirement will be slightly higher than the size of the database. Standard-8, PlusPF-8 and PlusPFP-8 databases require more than 8GB. | This setting is overridable by providing an explicit taxonomy, database or reference path in the other reference options. | Standard-8 |\n| database | string | Not required but can be used to specifically override Kraken2 database [.tar.gz or Directory]. | By default uses database chosen in database_set parameter. |  |\n| taxonomy | string | Not required but can be used to specifically override taxonomy database. Change the default to use a different taxonomy file  [.tar.gz or directory]. | By default NCBI taxonomy file will be downloaded and used. |  |\n| reference | string | Override the FASTA reference file selected by the database_set parameter. It can be a FASTA format reference sequence collection or a minimap2 MMI format index. | This option should be used in conjunction with the database parameter to specify a custom database. |  |\n| ref2taxid | string | Not required but can be used to specify a  ref2taxid mapping. Format is .tsv (refname  taxid), no header row. | By default uses ref2taxid for option chosen in database_set parameter. |  |\n| taxonomic_rank | string | Returns results at the taxonomic rank chosen. In the Kraken2 pipeline: set the level that Bracken will estimate abundance at. Default: S (species). Other possible options are K (kingdom level), P (phylum), C (class), O (order), F (family), and G (genus). |  | S |\n\n\n### Kraken2 Options\n\n| Nextflow parameter name  | Type | Description | Help | Default |\n|--------------------------|------|-------------|------|---------|\n| bracken_length | integer | Set the length value Bracken will use | Should be set to the length used to generate the kmer distribution file supplied in the Kraken database input directory. For the default datasets these will be set automatically. ncbi_16s_18s = 1000 , ncbi_16s_18s_28s_ITS = 1000 , PlusPF-8 = 300 |  |\n| kraken2_memory_mapping | boolean | Avoids loading database into RAM | Kraken 2 will by default load the database into process-local RAM; this flag will avoid doing so. It may be useful if the available RAM memory is lower than the size of the chosen database. | False |\n| include_kraken2_assignments | boolean | A per sample TSV file that indicates how each input sequence was classified as well as the taxon that has been assigned to each read. The TSV's will only be output on completion of the workflow and therefore not at all if using the real time option whilst running indefinitely. |  | False |\n| kraken2_confidence | number | Kraken2 Confidence score threshold. Default: 0.0. Valid interval: 0-1 | Apply a threshold to determine if a sequence is classified or unclassified. Please visit the following link for further details about how it works: https://github.com/DerrickWood/kraken2/wiki/Manual#confidence-scoring. | 0.0 |\n\n\n### Minimap2 Options\n\n| Nextflow parameter name  | Type | Description | Help | Default |\n|--------------------------|------|-------------|------|---------|\n| minimap2filter | string | Filter output of minimap2 by taxids inc. child nodes, E.g. \"9606,1404\" | Provide a list of taxids if you are only interested in certain ones in your minimap2 analysis outputs. |  |\n| minimap2exclude | boolean | Invert minimap2filter and exclude the given taxids instead | Exclude a list of taxids from analysis outputs. | False |\n| split_prefix | boolean | Enable if using a very large reference with minimap2 | If reference fasta large enough to require multipart index, set to true to use split-prefix option with minimap2. | False |\n| keep_bam | boolean | Copy bam files into the output directory. It also creates the configuration and reduced reference files needed to load the alignments in IGV. |  | False |\n| minimap2_by_reference | boolean | Add a table with the mean sequencing depth per reference, standard deviation and coefficient of variation. It adds a scatterplot of the sequencing depth vs. the coverage and a heatmap showing the depth per percentile to the report |  | False |\n| min_percent_identity | number | Minimum percentage of identity with the matched reference to define a sequence as classified; sequences with a value lower than this are defined as unclassified. |  | 90 |\n| min_ref_coverage | number | Minimum coverage value to define a sequence as classified; sequences with a coverage value lower than this are defined as unclassified. Use this option if you expect reads whose lengths are similar to the references' lengths. |  | 0 |\n\n\n### Antimicrobial Resistance Options\n\n| Nextflow parameter name  | Type | Description | Help | Default |\n|--------------------------|------|-------------|------|---------|\n| amr | boolean | Scan reads for antimicrobial resistance or virulence genes | Reads will be scanned using abricate and the chosen database (`--amr_db`) to identify any acquired antimicrobial resistance or virulence genes found present in the dataset. NOTE: It cannot identify mutational resistance genes. | False |\n| amr_db | string | Database of antimicrobial resistance or virulence genes to use. |  | resfinder |\n| amr_minid | integer | Threshold of required identity to report a match between a gene in the database and fastq reads. Valid interval: 0-100 |  | 80 |\n| amr_mincov | integer | Minimum coverage (breadth-of) threshold required to report a match between a gene in the database and fastq reads. Valid interval: 0-100. |  | 80 |\n\n\n### Report Options\n\n| Nextflow parameter name  | Type | Description | Help | Default |\n|--------------------------|------|-------------|------|---------|\n| abundance_threshold | number | Remove those taxa whose abundance is equal or lower than the chosen value. | To remove taxa with abundances lower than or equal to a relative value (compared to the total number of reads) use a decimal between 0-1 (1 not inclusive). To remove taxa with abundances lower than or equal to an absolute value, provide a number larger or equal to 1. | 0 |\n| n_taxa_barplot | integer | Number of most abundant taxa to be displayed in the barplot. The rest of taxa will be grouped under the \"Other\" category. |  | 9 |\n\n\n### Output Options\n\n| Nextflow parameter name  | Type | Description | Help | Default |\n|--------------------------|------|-------------|------|---------|\n| out_dir | string | Directory for output of all user-facing files. |  | output |\n\n\n### Advanced Options\n\n| Nextflow parameter name  | Type | Description | Help | Default |\n|--------------------------|------|-------------|------|---------|\n| min_len | integer | Specify read length lower limit. | Any reads shorter than this limit will not be included in the analysis. | 0 |\n| min_read_qual | number | Specify read quality lower limit. | Any reads with a quality lower than this limit will not be included in the analysis. |  |\n| max_len | integer | Specify read length upper limit | Any reads longer than this limit will not be included in the analysis. |  |\n| threads | integer | Maximum number of CPU threads to use in each parallel workflow task. | Several tasks in this workflow benefit from using multiple CPU threads. This option sets the number of CPU threads for all such processes. See server threads parameter for Kraken specific threads in the real_time pipeline. | 4 |\n\n\n\n\n\n\n## Outputs\n\nOutput files may be aggregated including information for all samples or provided per sample. Per-sample files will be prefixed with respective aliases and represented below as {{ alias }}.\n\n| Title | File path | Description | Per sample or aggregated |\n|-------|-----------|-------------|--------------------------|\n| workflow report | ./wf-metagenomics-report.html | Report for all samples. | aggregated |\n| Abundance table with counts per taxa | ./abundance_table_{{ taxonomic_rank }}.tsv | Per-taxa counts TSV, including all samples. | aggregated |\n| Bracken report file | ./bracken/{{ alias }}.kraken2_bracken.report | TSV file with the abundance of each taxa. See more info here: https://github.com/jenniferlu717/Bracken#output-kraken-style-bracken-report. | per-sample |\n| Kraken2 taxonomic assignment per read (Kraken2 pipeline) | ./kraken2/{{ alias }}.kraken2.report.txt | Lineage-aggregated counts. See more info here: https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown#sample-report-output-format. | per-sample |\n| Kraken2 taxonomic asignment per read (Kraken2 pipeline) | ./kraken2/{{ alias }}.kraken2.assignments.tsv | TSV file with the taxonomic assignment per read. See more info here: https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown#standard-kraken-output-format. | per-sample |\n| Host BAM file | ./host_bam/{{ alias }}.bam | BAM file generated from mapping filtered input reads to the host reference. | per-sample |\n| BAM index file of host reads | ./host_bam/{{ alias }}.bai | BAM index file generated from mapping filtered input reads to the host reference. | per-sample |\n| BAM file (minimap2) | ./bams/{{ alias }}.reference.bam | BAM file generated from mapping filtered input reads to the reference. | per-sample |\n| BAM index file (minimap2) | ./bams/{{ alias }}.reference.bam.bai | Index file generated from mapping filtered input reads to the reference. | per-sample |\n| BAM flagstat (minimap2) | ./bams/{{ alias }}.bamstats_results/bamstats.flagstat.tsv | Mapping results per reference | per-sample |\n| Minimap2 alignment statistics (minimap2) | ./bams/{{ alias }}.bamstats_results/bamstats.readstats.tsv.gz | Per read stats after aligning | per-sample |\n| JSON file with identified AMR genes (amr) | ./amr/{{ alias }}.json | JSON file with abricate results. See more info here: https://github.com/tseemann/abricate#output. | per-sample |\n| Reduced reference FASTA file | ./igv_reference/reduced_reference.fasta.gz | Reference FASTA file containing only those sequences that have reads mapped against them. | aggregated |\n| Index of the reduced reference FASTA file | ./igv_reference/reduced_reference.fasta.gz.fai | Index of the reference FASTA file containing only those sequences that have reads mapped against them. | aggregated |\n| GZI index of the reduced reference FASTA file | ./igv_reference/reduced_reference.fasta.gz.gzi | Index of the reference FASTA file containing only those sequences that have reads mapped against them. | aggregated |\n| JSON configuration file for IGV browser | ./igv.json | JSON configuration file to be loaded in IGV for visualising alignments against the reduced reference. | aggregated |\n\n\n\n\n## Pipeline overview\n\n### 1. Concatenate input files and generate per read stats\n\n[fastcat](https://github.com/epi2me-labs/fastcat) is used to concatenate input FASTQ files prior to downstream processing of the workflow. It will also output per-read stats including read lengths and average qualities.\n\nYou may want to choose which reads are analysed by filtering them using these flags `max_len`, `min_len`, `min_read_qual`, (see the [Inputs section](#advanced-options) for details).\n\n### 2. Remove host sequences (optional)\n\nWe have included an optional filtering step to remove any host sequences that map (using [Minimap2](https://github.com/lh3/minimap2)) against a provided host reference (e.g. human), which can be a FASTA file or a MMI index. To use this option provide the path to your host reference with the `exclude_host` parameter. The mapped reads are output in a BAM file and excluded from further analysis.\n\n```\nnextflow run epi2me-labs/wf-metagenomics --fastq test_data/case04/reads.fastq.gz --exclude_host test_data/case04/host.fasta.gz\n```\n\n### 3. Classify reads taxonomically\n\nThere are two different approaches to taxonomic classification:\n\n#### 3.1 Using Kraken2\n\n[Kraken2](https://github.com/DerrickWood/kraken2) provides the fastest method for the taxonomic classification of the reads. Then, [Bracken](https://github.com/jenniferlu717/Bracken) is used to provide an estimate of the species (or the selected taxonomic rank) abundance in the sample.\n\n##### 3.1.1 Running wf-metagenomics in real time\n\nThe Kraken2 mode can be used in real-time, allowing the workflow to run parallel with an ongoing sequencing run as read data is being produced by the Oxford Nanopore Technologies sequencing instrument. In this case, [Kraken2](https://github.com/DerrickWood/kraken2) is used with the [Kraken2-server](https://github.com/epi2me-labs/kraken2-server) and the user can visualise the classification of reads and species abundances in a real-time updating report.    \nIn real-time mode, the workflow processes new input files as they become available in batches of the specified size. Thus, this option cannot be used with a single fastq as input.    \n>Note: When using the workflow in real-time, the workflow will run indefinitely until a user interrupts the program (e.g with `ctrl+c` when on the command line). The workflow can be configured to complete automatically after a set number of reads have been analysed using the `read_limit` variable. Once this threshold has been reached, the program will emit a `STOP.fastq.gz` file into the fastq directory, which will instruct the workflow to complete. The \"STOP.fastq.gz\" file is then deleted.\n\n```\nnextflow run epi2me-labs/wf-metagenomics --fastq test_data/case01 --real_time --batch_size 1000 --read_limit 4000\n```\n\nIf running the Kraken2 pipeline **real_time** in a cluster, there are two options to enable the workflow to be able to communicate with the Kraken-server: \n\n1. Run a Kraken-server separately outside of the workflow.\n2. Submit the workflow job to run on a single node (i.e. running as if on a single local machine).\n\n>Notes on CPU resource of Kraken-server and client in the real time workflow\nThe real-time subworkflow uses a server process to handle Kraken2 classification requests. This allows the workflow to persist the sequence database in memory throughout the duration of processing. There are some parameters that may be worth considering to improve the performance of the workflow:\n+ port: The option specifies the local network port on which the server and clients will communicate.\n+ host: Network hostname (or IP address) for communication between Kraken2 server and clients. (See also external_kraken2 parameter).\n+ external_kraken2: Whether a pre-existing Kraken2 server should be used, rather than creating one as part of the workflow. By default the workflow assumes that it is running on a single host computer, and further that it should start its own Kraken2 server. It may be desirable to start a Kraken2 server outside of the workflow (for example to host a large database), in which case this option should be enabled. This option may be used in conjuction with the host option to specify that the Kraken2 server is running on a remote computer.\n+ server_threads: Number of CPU threads used by the Kraken2 server for classifying reads.\n+ kraken_clients: Number of clients that can connect at once to the Kraken-server for classifying reads. It should not be set to more than 4 fewer than the executor CPU limit.\n\n#### 3.2 Using Minimap2\n\n[Minimap2](https://github.com/lh3/minimap2) provides better resolution, but, depending on the reference database used, can take significantly more time. Also, running the workflow with minimap2 does not support real-time analysis.\n\n```\nnextflow run epi2me-labs/wf-metagenomics --fastq test_data/case01 --classifier minimap2\n```\n\nThe creation of alignment statistics plots can be enabled with the `minimap2_by_reference` flag. Using this option produces a table and scatter plot in the report showing sequencing depth and coverage of each reference. The report also contains a heatmap indicating the sequencing depth over relative genomic coordinates for the references with the highest coverage (references with a mean coverage of less than 1% of the one with the largest value are omitted).\n\nIn addition, the user can output BAM files in a folder called `bams` by using the option `keep_bam`. If the user provides a custom database, the workflow will also output the references with reads mappings, as well as an IGV configuration file. This configuration file allows the user to view the alignments in the EPI2ME Desktop Application in the Viewer tab. Note that the number of references can be reduced using the `abundance_threshold` option, which will select those references with a number of reads aligned higher than this value. Please, consider that the view of the alignment is highly dependent on the reference selected.\n\n### 4. Identify Antimicrobial Resistance Genes (AMR) (optional)\n\nThe workflow can be used to determine the presence of acquired antimicrobial resistance (AMR) or virulence genes within the dataset. It uses [ABRicate](https://github.com/tseemann/abricate) to scan reads against a database of AMR/virulence genes.\n\n```\nnextflow run epi2me-labs/wf-metagenomics --fastq path/to/fastq/ --database_set PlusPF-8 --amr\n```\n\n>Note: ABRicate can only report the presence of acquired AMR/virulence genes but cannot identify SNP-mediated antimicrobial resistance. \n\n### 5. Prepare output\n\nThe main output of the wf-metagenomics pipeline is the `wf-metagenomics-report.html` which can be found in the output directory. It contains a summary of read statistics, the taxonomic composition of the sample and some diversity metrics. The results shown in the report can also be customised with several options. For example, you can use `abundance_threshold` to remove all taxa less prevalent than the threshold from the abundance table. When setting this parameter to a natural number, taxa with fewer absolute counts are removed. You can also pass a decimal between 0.0-1.0 to drop taxa of lower relative abundance. Furthermore, `n_taxa_barplot` controls the number of taxa displayed in the bar plot and groups the rest under the category â€˜Otherâ€™.\n\nThe workflow output also contains Kraken and bracken reports for each sample. Additionally, the â€˜species-abundance.tsvâ€™ is a table with the counts of the different taxa per sample. You can use the flag `include_kraken2_assignments` to include a per sample TSV file that indicates how each input sequence was classified as well as the taxon that has been assigned to each read. This TSV file will only be output on completion of the workflow and therefore not at all if using the real time option whilst running indefinitely. This option is available in the Kraken2 pipeline.\n\n\n#### 5.1 Diversity indices\n\nSpecies diversity refers to the taxonomic composition in a specific microbial community. There are some useful concepts to take into account:\n* Richness: number of unique taxonomic groups present in the community,\n* Taxonomic group abundance: number of individuals of a particular taxonomic group present in the community,\n* Evenness: refers to the equitability of the different taxonomic groups in terms of their abundances.\n    Two different communities can host the same number of different taxonomic groups (i.e. they have the same richness), but they can have different evenness. For instance, if there is one taxon whose abundance is much larger in one community compared to the other.\n\nThere are three types of biodiversity measures described over a special scale <sup>[1](https://doi.org/10.2307/1218190), [2](https://doi.org/10.1016/B978-0-12-384719-5.00036-8)</sup>: alpha-, beta-, and gamma-diversity.\n* Alpha-diversity refers to the richness that occurs within a community given area within a region.\n* Beta-diversity defined as variation in the identities of species among sites, provides a direct link between biodiversity at local scales (alpha diversity) and the broader regional species pool (gamma diversity).\n* Gamma-diversity is the total observed richness within an entire region.\n\nTo provide a quick overview of the alpha-diversity of the microbial community, we provide some of the most common diversity metrics calculated for a specific taxonomic rank <sup>[3](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4224527/)</sup>, which can be chosen by the user with the `taxonomic_rank` parameter ('D'=Domain,'P'=Phylum, 'C'=Class, 'O'=Order, 'F'=Family, 'G'=Genus, 'S'=Species). By default, the rank is 'S' (species-level). Some of the included alpha diversity metrics are:\n\n* Shannon Diversity Index (H): Shannon entropy approaches zero if a community is almost entirely made up of a single taxon.\n\n```math\nH = -\\sum_{i=1}^{S}p_i*ln(p_i)\n```\n\n* Simpson's Diversity Index (D): The range is from 0 (low diversity) to 1 (high diversity).    \n\n```math\nD = \\sum_{i=1}^{S}p_i^2\n```\n\n* Pielou Index (J): The values range from 0 (presence of a dominant species) and 1 (maximum evennes).    \n\n```math\nJ = H/ln(S)\n```\n\n* Berger-Parker dominance index (BP): expresses the proportional importance of the most abundant type, i.e., the ratio of number of individuals of most abundant species to the total number of individuals of all the species in the sample.\n\n```math\nBP = n_i/N\n```\n   where n<sub>i</sub> refers to the counts of the most abundant taxon and N is the total of counts.     \n\n\n* Fisherâ€™s alpha: Fisher (see Fisher, 1943<sup>[4](https://doi.org/10.2307/1411)</sup>) noticed that only a few species tend to be abundant while most are represented by only a few individuals ('rare biosphere'). These differences in species abundance can be incorporated into species diversity measurements such as the Fisherâ€™s alpha. This index is based upon the logarithmic distribution of number of individuals of different species. \n\n```math\nS = \\alpha * ln(1 + N/\\alpha)\n```\n   where S is the total number of taxa, N is the total number of individuals in the sample. The value of Fisher's $`\\alpha`$ is calculated by iteration.\n\nThese indices are calculated by default using the original abundance table (see McMurdie and Holmes<sup>[5](https://pubmed.ncbi.nlm.nih.gov/24699258/)</sup>, 2014 and Willis<sup>[6](https://www.frontiersin.org/articles/10.3389/fmicb.2019.02407/full)</sup>, 2019). If you want to calculate them from a rarefied abundance table (i.e. all the samples have been subsampled to contain the same number of counts per sample, which is the 95% of the minimum number of total counts), you can download the rarefied table from the report.\n\nThe report also includes the rarefaction curve per sample which displays the mean of species richness for a subsample of reads (sample size). Generally, this curve initially grows rapidly, as most abundant species are sequenced and they add new taxa in the community, then slightly flattens due to the fact that 'rare' species are more difficult of being sampled, and because of that is more difficult to report an increase in the number of observed species.\n\n> Note: Within each rank, each named taxon is a unique unit. The counts are the number of reads assigned to that taxon. All `Unknown` sequences are considered as a unique taxon\n\n\n\n## Troubleshooting\n\n+ If the workflow fails please run it with the demo data set to ensure the workflow itself is working. This will help us determine if the issue is related to the environment, input parameters or a bug.\n+ See how to interpret some common nextflow exit codes [here](https://labs.epi2me.io/trouble-shooting/).\n+ When using the Minimap2 pipeline with a custom database, you must make sure that the `ref2taxid` and reference files are coherent, as well as the taxonomy database.\n+ If your device doesn't have the resources to use large Kraken2 databases (e.g. Standard-8, PlusPF-8 and PlusPFP-8), you can enable `kraken2_memory_mapping` to reduce the amount of memory required.\n\n\n\n\n## FAQ's\n\nIf your question is not answered here, please report any issues or suggestions on the [github issues](https://github.com/epi2me-labs/wf-metagenomics/issues) page or start a discussion on the [community](https://community.nanoporetech.com/). \n\n+ *Which database is used by default?* - By default, the workflow uses the Standard-8 in kraken2 pipelines and the NCBI 16S + 18S rRNA database in the minimap2 workflow. It will be downloaded the first time the workflow is run and re-used in subsequent runs.\n\n+ *Are more databases available?* - Other metagenomic databases (listed below) can be selected with the `database_set` parameter, but the workflow can also be used with a custom database if required (see [here](https://labs.epi2me.io/how-to-meta-offline/) for details).\n    * 16S, 18S, ITS\n        * ncbi_16s_18s and ncbi_16s_18s_28s_ITS:  Archaeal, bacterial and fungal 16S/18S and ITS data. There are two databases available using the data from [NCBI]https://www.ncbi.nlm.nih.gov/refseq/targetedloci/)\n        * SILVA_138_1: The [SILVA](https://www.arb-silva.de/) database (version 138) is also available. Note that SILVA uses its own set of taxids, which do not match the NCBI taxids. We provide the respective taxdump files, but if you prefer using the NCBI ones, you can create them from the SILVA files ([NCBI](https://www.arb-silva.de/no_cache/download/archive/current/Exports/taxonomy/ncbi/)). As the SILVA database uses genus level, the last taxonomic rank at which the analysis is carried out is genus (`taxonomic_rank G`).\n    * General databases\n        * Standard-8: It contains references for Archaea, Bacteria, viral, plasmid, human, UniVec_Core. To use this database the memory available to the workflow must be slightly higher than size of the database index (8GB).\n        * PlusPF-8: It contains references for Archaea, Bacteria, viral, plasmid, human, UniVec_Core, protozoa and fungi. To use this database the memory available to the workflow must be slightly higher than size of the database index (8GB).\n        * PlusPFP-8: It contains references for Archaea, Bacteria, viral, plasmid, human, UniVec_Core, protozoa, fungi and plant. To use this database the memory available to the workflow must be slightly higher than size of the database index (8GB).\n\n+ *How can I use Kraken2 indexes?* - There are different databases available [here](https://benlangmead.github.io/aws-indexes/k2).\n\n+ *How can I use custom databases?* - If you want to run the workflow using your own Kraken2 database, you'll need to provide the database and an associated taxonomy dump. For a custom Minimap2 reference database, you'll need to provide a reference FASTA (or MMI) and an associated ref2taxid file. For a guide on how to build and use custom databases, take a look at our [article on how to run wf-metagenomics offline](https://labs.epi2me.io/how-to-meta-offline/).\n\n+ *How can I run the workflow with less memory?* -\n    When running in Kraken mode, you can set the `kraken2_memory_mapping` parameter if the available memory is smaller than the size of the database.\n\n+ *How can I run the workflow offline?* - To run wf-metagenomics offline you can use the workflow to download the databases from the internet and prepare them for offline re-use later. If you want to use one of the databases supported out of the box by the workflow, you can run the workflow with your desired database and any input (for example, the test data). The database will be downloaded and prepared in a directory on your computer. Once the database has been prepared, it will be used automatically the next time you run the workflow without needing to be downloaded again. You can find advice on picking a suitable database in our [article on selecting databases for wf-metagenomics](https://labs.epi2me.io/metagenomic-databases/).\n\n+ *Which databases are available for AMR?* - By default, ABRicate is set to search for AMR genes present in the [Resfinder](https://bitbucket.org/genomicepidemiology/resfinder_db/src/master/) database. Users can choose from a number of databases using the `amr_db` parameter. \n\n    |```amr_db``` | Database |\n    |---------------|----------|\n    |```resfinder```| [Resfinder](https://bitbucket.org/genomicepidemiology/resfinder_db/src/master/)|\n    |```ecoli_vf```| [E. coli virulence factors](https://github.com/phac-nml/ecoli_vf)|\n    |```plasmidfinder```| [PlasmidFinder](https://bitbucket.org/genomicepidemiology/plasmidfinder_db/src/master/)|\n    |```card```| [Comprehensive Antibiotic Resistance Database](https://card.mcmaster.ca/)|\n    |```argannot```| [ARG-ANNOT](https://www.mediterranee-infection.com/acces-ressources/base-de-donnees/arg-annot-2/)|\n    |```vfdb```| [Virulence factor DB](http://www.mgc.ac.cn/VFs/)|\n    |```ncbi```| [NCBI AMRFinderPlus](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA313047)|\n    |```megares```| [MEGAres](https://www.meglab.org/megares/)|\n    |```ecoh```| [E. coli AMR DB from SRST2](https://github.com/katholt/srst2/tree/master/data)|\n\n+ *What does the `test_data` folder contain?* - This folder contains several small datasets, real and simulated, for testing the workflow with different parameters and use cases.\n\n+ *Is it possible to run the real time approach in the cloud?* - No, the real time pipeline is not yet available to be run in the cloud.\n\n\n\n## Related blog posts\n\n+ [How to build and use databases to run wf-metagenomics and wf-16s offline](https://labs.epi2me.io/how-to-meta-offline/).\n+ [Selecting the correct databases in the wf-metagenomics](https://labs.epi2me.io/metagenomic-databases/).\n\nSee the [EPI2ME website](https://labs.epi2me.io/) for lots of other resources and blog posts.\n\n\n\n\n","manifest":{"name":"epi2me-labs/wf-metagenomics","author":"Oxford Nanopore Technologies","homePage":"https://github.com/epi2me-labs/wf-metagenomics","description":"Identification of the origin of single reads from both amplicon-targeted and shotgun metagenomics sequencing.","mainScript":"main.nf","nextflowVersion":">=23.04.2","version":"v2.10.1"},"settings":{"tags":["metagenomics","amr"],"outdirParam":"out_dir"},"revisions":{"current":"ref: refs/heads/master","branches":["master","version_1_test"],"tags":["version-1-test"]}}}